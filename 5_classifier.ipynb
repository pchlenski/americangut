{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn americangut into a binary classification problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.read_h5ad(\"data/americangut_embeddings.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibd\n",
      "i do not have this condition                                         26122\n",
      "nan                                                                   5137\n",
      "diagnosed by a medical professional (doctor, physician assistant)     1089\n",
      "self-diagnosed                                                         219\n",
      "diagnosed by an alternative medicine practitioner                       37\n",
      "not provided                                                             3\n",
      "unspecified                                                              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def report(column, normalize=False):\n",
    "    \"\"\"Report on column values. Call this for manual inspection\"\"\"\n",
    "    print(adata.obs[column].str.lower().value_counts(normalize=normalize))\n",
    "\n",
    "\n",
    "report(\"ibd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "cancer_treatment\n",
      "nan                  31048\n",
      "surgery only           847\n",
      "chemotherapy           260\n",
      "not provided           188\n",
      "radiation therapy      173\n",
      "no treatment            87\n",
      "unspecified              5\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "cardiovascular_disease\n",
      "i do not have this condition                                         22371\n",
      "nan                                                                   9158\n",
      "diagnosed by a medical professional (doctor, physician assistant)     1041\n",
      "self-diagnosed                                                          30\n",
      "diagnosed by an alternative medicine practitioner                        6\n",
      "not provided                                                             2\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "cat\n",
      "no              21186\n",
      "yes              7243\n",
      "nan              4171\n",
      "false               6\n",
      "not provided        1\n",
      "true                1\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "cdiff\n",
      "i do not have this condition                                         22661\n",
      "nan                                                                   9426\n",
      "diagnosed by a medical professional (doctor, physician assistant)      394\n",
      "diagnosed by an alternative medicine practitioner                       78\n",
      "self-diagnosed                                                          44\n",
      "not provided                                                             4\n",
      "unspecified                                                              1\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "census_region\n",
      "nan             32586\n",
      "usa                15\n",
      "not provided        5\n",
      "south               1\n",
      "west                1\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "chickenpox\n",
      "yes             22329\n",
      "no               4453\n",
      "nan              4289\n",
      "not sure         1528\n",
      "true                7\n",
      "not provided        2\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "clinical_condition\n",
      "i do not have this condition                                         17829\n",
      "nan                                                                   9980\n",
      "diagnosed by a medical professional (doctor, physician assistant)     4475\n",
      "self-diagnosed                                                         212\n",
      "diagnosed by an alternative medicine practitioner                      107\n",
      "not provided                                                             4\n",
      "unspecified                                                              1\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "collection_timestamp\n",
      "nan                    2666\n",
      "2017-01-25t09:00:00     130\n",
      "2017-02-07t09:00:00      84\n",
      "2016-11-21t20:00:00      82\n",
      "2016-12-17t20:00:00      70\n",
      "                       ... \n",
      "2022-02-18t18:41:00       1\n",
      "2022-02-25t06:42:00       1\n",
      "2022-01-08t10:00:00       1\n",
      "2022-02-24t08:30:00       1\n",
      "2018-04-09t10:55:00       1\n",
      "Name: count, Length: 24955, dtype: int64\n",
      "category\n",
      "consume_animal_products_abx\n",
      "nan             8980\n",
      "yes             8695\n",
      "not sure        8615\n",
      "no              6313\n",
      "false              2\n",
      "not provided       2\n",
      "true               1\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "contraceptive\n",
      "no                                               23071\n",
      "nan                                               7241\n",
      "yes, i am taking the \"pill                        1311\n",
      "yes, i use a hormonal iud (mirena)                 774\n",
      "yes, i use the nuvaring                             91\n",
      "yes, i use an injected contraceptive (dmpa)         83\n",
      "yes, i use a contraceptive patch (ortho-evra)       23\n",
      "not provided                                        13\n",
      "unspecified                                          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use this to build up a master list\n",
    "\n",
    "for col in adata.obs.columns[50:60]:\n",
    "    print(adata.obs.dtypes[col])\n",
    "    if adata.obs.dtypes[col] == \"category\":\n",
    "        report(col)\n",
    "\n",
    "neg_master = [\"no\", \"false\", \"i do not have this condition\", \"never\"]\n",
    "\n",
    "pos_master = [\n",
    "    \"yes\",\n",
    "    \"true\",\n",
    "    \"diagnosed by a medical professional (doctor, physician assistant)\",\n",
    "    \"self-diagnosed\",\n",
    "    \"diagnosed by an alternative medicine practitioner\",\n",
    "    \"rarely (less than once/week)\",\n",
    "    \"rarely (a few times/month)\",\n",
    "    \"occasionally (1-2 times/week)\",\n",
    "    \"regularly (3-5 times/week)\",\n",
    "    \"daily\",\n",
    "]\n",
    "\n",
    "nan_master = [\"nan\", \"not provided\", \"not sure\", \"not collected\", \"unspecified\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(\n",
    "    column,\n",
    "    pos_vals=pos_master,\n",
    "    neg_vals=neg_master,\n",
    "    nan_vals=nan_master,\n",
    "    data=adata.X.toarray(),\n",
    "    balance=False,\n",
    "    seed=None,\n",
    "):\n",
    "    vals = adata.obs[column].str.lower()\n",
    "    nan_vals = vals.isna() | vals.isin(nan_vals)\n",
    "    pos_vals = vals.isin(pos_vals)\n",
    "    neg_vals = vals.isin(neg_vals)\n",
    "    assert not (pos_vals & neg_vals).any()\n",
    "    try:\n",
    "        assert (pos_vals | neg_vals | nan_vals).all()\n",
    "    except AssertionError:\n",
    "        print(column)\n",
    "        print(vals[~(pos_vals | neg_vals | nan_vals)])\n",
    "\n",
    "    X = np.array(data)[~nan_vals]\n",
    "    y = np.array(pos_vals)[~nan_vals]\n",
    "\n",
    "    n_pos = y.sum()\n",
    "    n_neg = (~y).sum()\n",
    "\n",
    "    if balance:\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        # Balance the classes\n",
    "        if n_pos > n_neg:\n",
    "            drop = np.random.choice(\n",
    "                np.where(y)[0], n_pos - n_neg, replace=False\n",
    "            )\n",
    "        elif n_neg > n_pos:\n",
    "            drop = np.random.choice(\n",
    "                np.where(~y)[0], n_neg - n_pos, replace=False\n",
    "            )\n",
    "        X = np.delete(X, drop, axis=0)\n",
    "        y = np.delete(y, drop, axis=0)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ibd, y_ibd = classify(column=\"ibd\", balance=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m X, y \u001b[39m=\u001b[39m classify(\n\u001b[1;32m     19\u001b[0m     column\u001b[39m=\u001b[39mcolumn, data\u001b[39m=\u001b[39madata\u001b[39m.\u001b[39mobsm[embedding], balance\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m xgb \u001b[39m=\u001b[39m XGBClassifier()\n\u001b[0;32m---> 22\u001b[0m score \u001b[39m=\u001b[39m cross_val_score(xgb, X, y, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     24\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(X)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00membedding\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mscore\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ± \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m.\u001b[39mstd()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m results\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     27\u001b[0m     {\n\u001b[1;32m     28\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m: column,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     }\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Basic experiment: XGBoost in different embeddings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "\n",
    "X_np = adata.X.toarray()\n",
    "\n",
    "NDIM = 64\n",
    "\n",
    "results = []\n",
    "for column in [\"ibd\", \"asd\", \"vivid_dreams\"]:\n",
    "    for embedding in [\n",
    "        f\"hyp_mix_{NDIM}\",\n",
    "        f\"poi_mix_{NDIM}\",\n",
    "        f\"euc_mix_{NDIM}\",\n",
    "        f\"pca_{NDIM}\",\n",
    "    ]:\n",
    "        X, y = classify(\n",
    "            column=column, data=adata.obsm[embedding], balance=True, seed=42\n",
    "        )\n",
    "        xgb = XGBClassifier()\n",
    "        score = cross_val_score(xgb, X, y, cv=5)\n",
    "        print(\n",
    "            f\"{column} ({len(X)})\\t{embedding}\\t{score.mean():.4f} ± {score.std():.4f}\"\n",
    "        )\n",
    "        results.append(\n",
    "            {\n",
    "                \"column\": column,\n",
    "                \"embedding\": embedding,\n",
    "                \"score\": score.mean(),\n",
    "                \"score_std\": score.std(),\n",
    "            }\n",
    "        )\n",
    "        print()\n",
    "\n",
    "results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " [Text(0, 0, 'ibd hyp_mix_64'),\n",
       "  Text(1, 0, 'ibd poi_mix_64'),\n",
       "  Text(2, 0, 'ibd euc_mix_64'),\n",
       "  Text(3, 0, 'ibd pca_64'),\n",
       "  Text(4, 0, 'asd hyp_mix_64'),\n",
       "  Text(5, 0, 'asd poi_mix_64'),\n",
       "  Text(6, 0, 'asd euc_mix_64'),\n",
       "  Text(7, 0, 'asd pca_64'),\n",
       "  Text(8, 0, 'vivid_dreams hyp_mix_64'),\n",
       "  Text(9, 0, 'vivid_dreams poi_mix_64'),\n",
       "  Text(10, 0, 'vivid_dreams euc_mix_64'),\n",
       "  Text(11, 0, 'vivid_dreams pca_64')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a bar plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "plt.bar(\n",
    "    results[\"column\"] + \" \" + results[\"embedding\"],\n",
    "    results[\"score\"],\n",
    "    yerr=results[\"score_std\"],\n",
    ")\n",
    "plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping weight_units with 32608 nan values\n",
      "Dropping weight_kg with 32608 nan values\n",
      "Dropping weight_cat with 32589 nan values\n",
      "Dropping weekend_wake_time with 32608 nan values\n",
      "Dropping weekend_sleep_time with 32608 nan values\n",
      "Dropping weekday_wake_time with 32608 nan values\n",
      "Dropping weekday_sleep_time with 32608 nan values\n",
      "Dropping vioscreen_zinc with 32608 nan values\n",
      "Dropping vioscreen_xylitol with 32608 nan values\n",
      "Dropping vioscreen_whole_grain_servings with 32608 nan values\n",
      "Dropping vioscreen_wgrain with 32608 nan values\n",
      "Dropping vioscreen_weight with 32608 nan values\n",
      "Dropping vioscreen_water with 32608 nan values\n",
      "Dropping vioscreen_vitk with 32608 nan values\n",
      "Dropping vioscreen_vite_iu with 32608 nan values\n",
      "Dropping vioscreen_vitd_iu with 32608 nan values\n",
      "Dropping vioscreen_vitd3 with 32608 nan values\n",
      "Dropping vioscreen_vitd2 with 32608 nan values\n",
      "Dropping vioscreen_vitd with 32608 nan values\n",
      "Dropping vioscreen_vitc with 32608 nan values\n",
      "Dropping vioscreen_vitb6 with 32608 nan values\n",
      "Dropping vioscreen_vitb12 with 32608 nan values\n",
      "Dropping vioscreen_vita_re with 32608 nan values\n",
      "Dropping vioscreen_vita_rae with 32608 nan values\n",
      "Dropping vioscreen_vita_iu with 32608 nan values\n",
      "Dropping vioscreen_visit with 32608 nan values\n",
      "Dropping vioscreen_vegsumm with 32608 nan values\n",
      "Dropping vioscreen_vegetable_servings with 32608 nan values\n",
      "Dropping vioscreen_veg5_day with 32608 nan values\n",
      "Dropping vioscreen_valine with 32608 nan values\n",
      "Dropping vioscreen_v_total with 32608 nan values\n",
      "Dropping vioscreen_v_tomato with 32608 nan values\n",
      "Dropping vioscreen_v_starcy with 32608 nan values\n",
      "Dropping vioscreen_v_potato with 32608 nan values\n",
      "Dropping vioscreen_v_other with 32608 nan values\n",
      "Dropping vioscreen_v_orange with 32608 nan values\n",
      "Dropping vioscreen_v_drkgr with 32608 nan values\n",
      "Dropping vioscreen_user_id with 32608 nan values\n",
      "Dropping vioscreen_tyrosine with 32608 nan values\n",
      "Dropping vioscreen_tryptoph with 32608 nan values\n",
      "Dropping vioscreen_totsugar with 32608 nan values\n",
      "Dropping vioscreen_totfolat with 32608 nan values\n",
      "Dropping vioscreen_totcla with 32608 nan values\n",
      "Dropping vioscreen_totaltfa with 32608 nan values\n",
      "Dropping vioscreen_time with 32608 nan values\n",
      "Dropping vioscreen_threonin with 32608 nan values\n",
      "Dropping vioscreen_thiamin with 32608 nan values\n",
      "Dropping vioscreen_tgrain with 32608 nan values\n",
      "Dropping vioscreen_tfa182t with 32608 nan values\n",
      "Dropping vioscreen_tfa181t with 32608 nan values\n",
      "Dropping vioscreen_tfa161t with 32608 nan values\n",
      "Dropping vioscreen_tagatose with 32608 nan values\n",
      "Dropping vioscreen_sweet_servings with 32608 nan values\n",
      "Dropping vioscreen_sucrose with 32608 nan values\n",
      "Dropping vioscreen_sucrlose with 32608 nan values\n",
      "Dropping vioscreen_sucpoly with 32608 nan values\n",
      "Dropping vioscreen_subject_id with 32608 nan values\n",
      "Dropping vioscreen_started with 32608 nan values\n",
      "Dropping vioscreen_starch with 32608 nan values\n",
      "Dropping vioscreen_srvid with 32608 nan values\n",
      "Dropping vioscreen_sorbitol with 32608 nan values\n",
      "Dropping vioscreen_sodium with 32608 nan values\n",
      "Dropping vioscreen_sfatot with 32608 nan values\n",
      "Dropping vioscreen_sfa80 with 32608 nan values\n",
      "Dropping vioscreen_sfa60 with 32608 nan values\n",
      "Dropping vioscreen_sfa40 with 32608 nan values\n",
      "Dropping vioscreen_sfa220 with 32608 nan values\n",
      "Dropping vioscreen_sfa200 with 32608 nan values\n",
      "Dropping vioscreen_sfa180 with 32608 nan values\n",
      "Dropping vioscreen_sfa170 with 32608 nan values\n",
      "Dropping vioscreen_sfa160 with 32608 nan values\n",
      "Dropping vioscreen_sfa140 with 32608 nan values\n",
      "Dropping vioscreen_sfa120 with 32608 nan values\n",
      "Dropping vioscreen_sfa100 with 32608 nan values\n",
      "Dropping vioscreen_serine with 32608 nan values\n",
      "Dropping vioscreen_selenium with 32608 nan values\n",
      "Dropping vioscreen_scfv with 32608 nan values\n",
      "Dropping vioscreen_scf with 32608 nan values\n",
      "Dropping vioscreen_satoco with 32608 nan values\n",
      "Dropping vioscreen_salad_vegetable_servings with 32608 nan values\n",
      "Dropping vioscreen_sacchar with 32608 nan values\n",
      "Dropping vioscreen_ribofla with 32608 nan values\n",
      "Dropping vioscreen_rgrain with 32608 nan values\n",
      "Dropping vioscreen_retinol with 32608 nan values\n",
      "Dropping vioscreen_recno with 32608 nan values\n",
      "Dropping vioscreen_questionnaire with 32608 nan values\n",
      "Dropping vioscreen_protveg with 32608 nan values\n",
      "Dropping vioscreen_protocol with 32608 nan values\n",
      "Dropping vioscreen_protein with 32608 nan values\n",
      "Dropping vioscreen_protanim with 32608 nan values\n",
      "Dropping vioscreen_proline with 32608 nan values\n",
      "Dropping vioscreen_procdate with 32608 nan values\n",
      "Dropping vioscreen_potass with 32608 nan values\n",
      "Dropping vioscreen_pinitol with 32608 nan values\n",
      "Dropping vioscreen_phytic with 32608 nan values\n",
      "Dropping vioscreen_phosphor with 32608 nan values\n",
      "Dropping vioscreen_phenylal with 32608 nan values\n",
      "Dropping vioscreen_pfatot with 32608 nan values\n",
      "Dropping vioscreen_pfa226 with 32608 nan values\n",
      "Dropping vioscreen_pfa225 with 32608 nan values\n",
      "Dropping vioscreen_pfa205 with 32608 nan values\n",
      "Dropping vioscreen_pfa204 with 32608 nan values\n",
      "Dropping vioscreen_pfa184 with 32608 nan values\n",
      "Dropping vioscreen_pfa183 with 32608 nan values\n",
      "Dropping vioscreen_pfa182 with 32608 nan values\n",
      "Dropping vioscreen_pectins with 32608 nan values\n",
      "Dropping vioscreen_pantothe with 32608 nan values\n",
      "Dropping vioscreen_oxalicm with 32608 nan values\n",
      "Dropping vioscreen_oxalic with 32608 nan values\n",
      "Dropping vioscreen_omega3 with 32608 nan values\n",
      "Dropping vioscreen_nutrient_recommendation with 32608 nan values\n",
      "Dropping vioscreen_non_fried_fish_servings with 32608 nan values\n",
      "Dropping vioscreen_nitrogen with 32608 nan values\n",
      "Dropping vioscreen_niacineq with 32608 nan values\n",
      "Dropping vioscreen_niacin with 32608 nan values\n",
      "Dropping vioscreen_nccglgr with 32608 nan values\n",
      "Dropping vioscreen_nccglbr with 32608 nan values\n",
      "Dropping vioscreen_natoco with 32608 nan values\n",
      "Dropping vioscreen_multivitamin_freq with 32608 nan values\n",
      "Dropping vioscreen_multivitamin with 32608 nan values\n",
      "Dropping vioscreen_multi_calcium_dose with 32608 nan values\n",
      "Dropping vioscreen_multi_calcium_avg with 32608 nan values\n",
      "Dropping vioscreen_mfatot with 32608 nan values\n",
      "Dropping vioscreen_mfa221 with 32608 nan values\n",
      "Dropping vioscreen_mfa201 with 32608 nan values\n",
      "Dropping vioscreen_mfa181 with 32608 nan values\n",
      "Dropping vioscreen_mfa161 with 32608 nan values\n",
      "Dropping vioscreen_mfa141 with 32608 nan values\n",
      "Dropping vioscreen_methion with 32608 nan values\n",
      "Dropping vioscreen_methhis3 with 32608 nan values\n",
      "Dropping vioscreen_mannitol with 32608 nan values\n",
      "Dropping vioscreen_mangan with 32608 nan values\n",
      "Dropping vioscreen_maltose with 32608 nan values\n",
      "Dropping vioscreen_maltitol with 32608 nan values\n",
      "Dropping vioscreen_magnes with 32608 nan values\n",
      "Dropping vioscreen_m_soy with 32608 nan values\n",
      "Dropping vioscreen_m_poult with 32608 nan values\n",
      "Dropping vioscreen_m_organ with 32608 nan values\n",
      "Dropping vioscreen_m_nutsd with 32608 nan values\n",
      "Dropping vioscreen_m_mpf with 32608 nan values\n",
      "Dropping vioscreen_m_meat with 32608 nan values\n",
      "Dropping vioscreen_m_frank with 32608 nan values\n",
      "Dropping vioscreen_m_fish_lo with 32608 nan values\n",
      "Dropping vioscreen_m_fish_hi with 32608 nan values\n",
      "Dropping vioscreen_m_egg with 32608 nan values\n",
      "Dropping vioscreen_lysine with 32608 nan values\n",
      "Dropping vioscreen_lycopene with 32608 nan values\n",
      "Dropping vioscreen_lutzeax with 32608 nan values\n",
      "Dropping vioscreen_low_fat_dairy_serving with 32608 nan values\n",
      "Dropping vioscreen_line_gi with 32608 nan values\n",
      "Dropping vioscreen_leucine with 32608 nan values\n",
      "Dropping vioscreen_legumes with 32608 nan values\n",
      "Dropping vioscreen_lactose with 32608 nan values\n",
      "Dropping vioscreen_lactitol with 32608 nan values\n",
      "Dropping vioscreen_juice_servings with 32608 nan values\n",
      "Dropping vioscreen_joules with 32608 nan values\n",
      "Dropping vioscreen_isomalt with 32608 nan values\n",
      "Dropping vioscreen_isoleuc with 32608 nan values\n",
      "Dropping vioscreen_iron with 32608 nan values\n",
      "Dropping vioscreen_inositol with 32608 nan values\n",
      "Dropping vioscreen_histidin with 32608 nan values\n",
      "Dropping vioscreen_height with 32608 nan values\n",
      "Dropping vioscreen_hei_whl_grains with 32608 nan values\n",
      "Dropping vioscreen_hei_veg with 32608 nan values\n",
      "Dropping vioscreen_hei_sol_fat_alc_add_sug with 32608 nan values\n",
      "Dropping vioscreen_hei_sodium with 32608 nan values\n",
      "Dropping vioscreen_hei_score with 32608 nan values\n",
      "Dropping vioscreen_hei_sat_fat with 32608 nan values\n",
      "Dropping vioscreen_hei_oils with 32608 nan values\n",
      "Dropping vioscreen_hei_non_juice_frt with 32608 nan values\n",
      "Dropping vioscreen_hei_milk with 32608 nan values\n",
      "Dropping vioscreen_hei_meat_beans with 32608 nan values\n",
      "Dropping vioscreen_hei_grains with 32608 nan values\n",
      "Dropping vioscreen_hei_fruit with 32608 nan values\n",
      "Dropping vioscreen_hei_drk_g_org_veg_leg with 32608 nan values\n",
      "Dropping vioscreen_hei2010_whole_grains with 32608 nan values\n",
      "Dropping vioscreen_hei2010_whole_fruit with 32608 nan values\n",
      "Dropping vioscreen_hei2010_veg with 32608 nan values\n",
      "Dropping vioscreen_hei2010_sodium with 32608 nan values\n",
      "Dropping vioscreen_hei2010_sea_foods_plant_protiens with 32608 nan values\n",
      "Dropping vioscreen_hei2010_score with 32608 nan values\n",
      "Dropping vioscreen_hei2010_refined_grains with 32608 nan values\n",
      "Dropping vioscreen_hei2010_protien_foods with 32608 nan values\n",
      "Dropping vioscreen_hei2010_greens_beans with 32608 nan values\n",
      "Dropping vioscreen_hei2010_fruit with 32608 nan values\n",
      "Dropping vioscreen_hei2010_fatty_acids with 32608 nan values\n",
      "Dropping vioscreen_hei2010_empty_calories with 32608 nan values\n",
      "Dropping vioscreen_hei2010_dairy with 32608 nan values\n",
      "Dropping vioscreen_grams with 32608 nan values\n",
      "Dropping vioscreen_glycitn with 32608 nan values\n",
      "Dropping vioscreen_glycine with 32608 nan values\n",
      "Dropping vioscreen_glutamic with 32608 nan values\n",
      "Dropping vioscreen_glucose with 32608 nan values\n",
      "Dropping vioscreen_gltc with 32608 nan values\n",
      "Dropping vioscreen_glac with 32608 nan values\n",
      "Dropping vioscreen_genistn with 32608 nan values\n",
      "Dropping vioscreen_gender with 32608 nan values\n",
      "Dropping vioscreen_gammtoco with 32608 nan values\n",
      "Dropping vioscreen_galactos with 32608 nan values\n",
      "Dropping vioscreen_g_whl with 32608 nan values\n",
      "Dropping vioscreen_g_total with 32608 nan values\n",
      "Dropping vioscreen_g_nwhl with 32608 nan values\n",
      "Dropping vioscreen_fruit_servings with 32608 nan values\n",
      "Dropping vioscreen_fructose with 32608 nan values\n",
      "Dropping vioscreen_frtsumm with 32608 nan values\n",
      "Dropping vioscreen_frt5_day with 32608 nan values\n",
      "Dropping vioscreen_fried_food_servings with 32608 nan values\n",
      "Dropping vioscreen_fried_fish_servings with 32608 nan values\n",
      "Dropping vioscreen_formontn with 32608 nan values\n",
      "Dropping vioscreen_fol_syn with 32608 nan values\n",
      "Dropping vioscreen_fol_nat with 32608 nan values\n",
      "Dropping vioscreen_fol_deqv with 32608 nan values\n",
      "Dropping vioscreen_fish_servings with 32608 nan values\n",
      "Dropping vioscreen_finished with 32608 nan values\n",
      "Dropping vioscreen_fibinso with 32608 nan values\n",
      "Dropping vioscreen_fibh2o with 32608 nan values\n",
      "Dropping vioscreen_fiber with 32608 nan values\n",
      "Dropping vioscreen_fat with 32608 nan values\n",
      "Dropping vioscreen_f_total with 32608 nan values\n",
      "Dropping vioscreen_f_other with 32608 nan values\n",
      "Dropping vioscreen_f_nj_total with 32608 nan values\n",
      "Dropping vioscreen_f_nj_other with 32608 nan values\n",
      "Dropping vioscreen_f_nj_citmlb with 32608 nan values\n",
      "Dropping vioscreen_f_citmlb with 32608 nan values\n",
      "Dropping vioscreen_erythr with 32608 nan values\n",
      "Dropping vioscreen_email with 32608 nan values\n",
      "Dropping vioscreen_eer with 32608 nan values\n",
      "Dropping vioscreen_dob with 32608 nan values\n",
      "Dropping vioscreen_discfat_sol with 32608 nan values\n",
      "Dropping vioscreen_discfat_oil with 32608 nan values\n",
      "Dropping vioscreen_delttoco with 32608 nan values\n",
      "Dropping vioscreen_database with 32608 nan values\n",
      "Dropping vioscreen_daidzein with 32608 nan values\n",
      "Dropping vioscreen_d_yogurt with 32608 nan values\n",
      "Dropping vioscreen_d_total with 32608 nan values\n",
      "Dropping vioscreen_d_tot_soym with 32608 nan values\n",
      "Dropping vioscreen_d_milk with 32608 nan values\n",
      "Dropping vioscreen_d_cheese with 32608 nan values\n",
      "Dropping vioscreen_cystine with 32608 nan values\n",
      "Dropping vioscreen_coumest with 32608 nan values\n",
      "Dropping vioscreen_copper with 32608 nan values\n",
      "Dropping vioscreen_clat10c12 with 32608 nan values\n",
      "Dropping vioscreen_clac9t11 with 32608 nan values\n",
      "Dropping vioscreen_choline with 32608 nan values\n",
      "Dropping vioscreen_cholest with 32608 nan values\n",
      "Dropping vioscreen_carbo with 32608 nan values\n",
      "Dropping vioscreen_calories with 32608 nan values\n",
      "Dropping vioscreen_calcium_servings with 32608 nan values\n",
      "Dropping vioscreen_calcium_from_dairy_servings with 32608 nan values\n",
      "Dropping vioscreen_calcium_freq with 32608 nan values\n",
      "Dropping vioscreen_calcium_dose with 32608 nan values\n",
      "Dropping vioscreen_calcium_avg with 32608 nan values\n",
      "Dropping vioscreen_calcium with 32608 nan values\n",
      "Dropping vioscreen_caffeine with 32608 nan values\n",
      "Dropping vioscreen_bmi with 32608 nan values\n",
      "Dropping vioscreen_biochana with 32608 nan values\n",
      "Dropping vioscreen_betatoco with 32608 nan values\n",
      "Dropping vioscreen_betaine with 32608 nan values\n",
      "Dropping vioscreen_betacryp with 32608 nan values\n",
      "Dropping vioscreen_betacar with 32608 nan values\n",
      "Dropping vioscreen_bcodeid with 32608 nan values\n",
      "Dropping vioscreen_avcarb with 32608 nan values\n",
      "Dropping vioscreen_aspartic with 32608 nan values\n",
      "Dropping vioscreen_aspartam with 32608 nan values\n",
      "Dropping vioscreen_ash with 32608 nan values\n",
      "Dropping vioscreen_arginine with 32608 nan values\n",
      "Dropping vioscreen_alphtoco with 32608 nan values\n",
      "Dropping vioscreen_alphtoce with 32608 nan values\n",
      "Dropping vioscreen_alphacar with 32608 nan values\n",
      "Dropping vioscreen_alcohol_servings with 32608 nan values\n",
      "Dropping vioscreen_alcohol with 32608 nan values\n",
      "Dropping vioscreen_alanine with 32608 nan values\n",
      "Dropping vioscreen_age with 32608 nan values\n",
      "Dropping vioscreen_adsugtot with 32608 nan values\n",
      "Dropping vioscreen_addsugar with 32608 nan values\n",
      "Dropping vioscreen_add_sug with 32608 nan values\n",
      "Dropping vioscreen_activity_level with 32608 nan values\n",
      "Dropping vioscreen_acesupot with 32608 nan values\n",
      "Dropping vioscreen_a_cal with 32608 nan values\n",
      "Dropping vioscreen_a_bev with 32608 nan values\n",
      "Dropping toilet_water_access with 32589 nan values\n",
      "Dropping thdmi_cohort with 31072 nan values\n",
      "Dropping surf_weetsuit with 32129 nan values\n",
      "Dropping surf_wax with 32141 nan values\n",
      "Dropping surf_travel_frequency with 32191 nan values\n",
      "Dropping surf_travel_distance with 32140 nan values\n",
      "Dropping surf_sunscreen_frequency with 32138 nan values\n",
      "Dropping surf_sunscreen with 32214 nan values\n",
      "Dropping surf_stance with 32135 nan values\n",
      "Dropping surf_shower_frequency with 32130 nan values\n",
      "Dropping surf_local_break with 32115 nan values\n",
      "Dropping surf_loal_break_frequency with 32127 nan values\n",
      "Dropping surf_frequency with 32129 nan values\n",
      "Dropping surf_board_type with 32135 nan values\n",
      "Dropping subset_ibd with 32542 nan values\n",
      "Dropping subset_healthy with 32542 nan values\n",
      "Dropping subset_diabetes with 32542 nan values\n",
      "Dropping subset_bmi with 32542 nan values\n",
      "Dropping subset_antibiotic_history with 32542 nan values\n",
      "Dropping subset_age with 32542 nan values\n",
      "Dropping state with 32272 nan values\n",
      "Dropping sleep_quality with 32608 nan values\n",
      "Dropping setting with 32589 nan values\n",
      "Dropping qiita_study_id with only one unique value\n",
      "Dropping public with only one unique value\n",
      "Dropping pm_useful with 32608 nan values\n",
      "Dropping pm_understand_results with 32608 nan values\n",
      "Dropping pm_shared_who_unspecified with 32608 nan values\n",
      "Dropping pm_shared_who_specialty_physician_eg_gastroenterologist with 32608 nan values\n",
      "Dropping pm_shared_who_primary_care_physician with 32608 nan values\n",
      "Dropping pm_shared_who_posteddiscussed_on_social_networking_site_ie_facebook with 32608 nan values\n",
      "Dropping pm_shared_who_posteddiscussed_on_data_sharing_platform_ie_open_humans with 32608 nan values\n",
      "Dropping pm_shared_who_posteddiscussed_on_an_online_patienthealth_platform_ie_patientslikeme with 32608 nan values\n",
      "Dropping pm_shared_who_other_medical_or_health_professional with 32608 nan values\n",
      "Dropping pm_shared_who_other with 32608 nan values\n",
      "Dropping pm_shared_who_nutritionistdietician with 32608 nan values\n",
      "Dropping pm_shared_who_friends with 32608 nan values\n",
      "Dropping pm_shared_who_family_members with 32608 nan values\n",
      "Dropping pm_shared_who_colleagues with 32608 nan values\n",
      "Dropping pm_shared_who with 32608 nan values\n",
      "Dropping pm_shared_pcp_changes_what_unspecified with 32608 nan values\n",
      "Dropping pm_shared_pcp_changes_what_referral_to_a_specialist_eg_gastroenterologist with 32608 nan values\n",
      "Dropping pm_shared_pcp_changes_what_other with 32608 nan values\n",
      "Dropping pm_shared_pcp_changes_what_ordered_additional_labs_tests_or_procedures with 32608 nan values\n",
      "Dropping pm_shared_pcp_changes_what_change_in_medication_ie_starting_stopping_or_changing_the_dose_of_a_prescription with 32608 nan values\n",
      "Dropping pm_shared_pcp_changes_what_change_in_behaviorallifestyle_recommendations_eg_start_probiotic with 32608 nan values\n",
      "Dropping pm_shared_pcp_changes_what with 32608 nan values\n",
      "Dropping pm_shared_pcp_changes with 32608 nan values\n",
      "Dropping pm_shared_pcp with 32608 nan values\n",
      "Dropping pm_shared with 32608 nan values\n",
      "Dropping pm_recontact with 32608 nan values\n",
      "Dropping pm_participation_reason_unspecified with 32608 nan values\n",
      "Dropping pm_participation_reason_the_study_seemed_fun_and_entertaining with 32608 nan values\n",
      "Dropping pm_participation_reason_professional_interest_in_the_microbiome with 32608 nan values\n",
      "Dropping pm_participation_reason_people_in_my_family_or_social_network_have_done_it with 32608 nan values\n",
      "Dropping pm_participation_reason_other with 32608 nan values\n",
      "Dropping pm_participation_reason_interest_in_contributing_to_science with 32608 nan values\n",
      "Dropping pm_participation_reason_i_have_other_microbiomerelevant_health_problems with 32608 nan values\n",
      "Dropping pm_participation_reason_i_have_gastrointestinal_problems with 32608 nan values\n",
      "Dropping pm_participation_reason_general_curiosityinterest_in_learning_about_my_microbiome with 32608 nan values\n",
      "Dropping pm_participation_reason_desire_to_improve_my_health with 32608 nan values\n",
      "Dropping pm_participation_reason with 32608 nan values\n",
      "Dropping pm_name with 32608 nan values\n",
      "Dropping pm_lifestyle_change_how_unspecified with 32608 nan values\n",
      "Dropping pm_lifestyle_change_how_other with 32608 nan values\n",
      "Dropping pm_lifestyle_change_how_change_in_use_of_nutritional_supplements_or_vitamins with 32608 nan values\n",
      "Dropping pm_lifestyle_change_how_change_in_physical_environment_ie_adopting_or_getting_rid_of_a_pet_cleaning_more_or_less_often with 32608 nan values\n",
      "Dropping pm_lifestyle_change_how_change_in_exercise with 32608 nan values\n",
      "Dropping pm_lifestyle_change_how_change_in_diet_ie_taking_a_probiotic with 32608 nan values\n",
      "Dropping pm_lifestyle_change_how_change_in_alcohol_or_tobacco_use_ie_starting_stopping_or_changing_amount_consumed with 32608 nan values\n",
      "Dropping pm_lifestyle_change_how with 32608 nan values\n",
      "Dropping pm_lifestyle_change with 32608 nan values\n",
      "Dropping pm_health with 32608 nan values\n",
      "Dropping pm_gender with 32608 nan values\n",
      "Dropping pm_gastro_problems_unspecified with 32608 nan values\n",
      "Dropping pm_gastro_problems_other with 32608 nan values\n",
      "Dropping pm_gastro_problems_irritable_bowel_syndrome_ibs with 32608 nan values\n",
      "Dropping pm_gastro_problems_i_have_had_surgery_on_my_intestines with 32608 nan values\n",
      "Dropping pm_gastro_problems_gastrointestinal_cancer with 32608 nan values\n",
      "Dropping pm_gastro_problems_frequent_more_than_once_a_week_diarrhea with 32608 nan values\n",
      "Dropping pm_gastro_problems_frequent_more_than_once_a_week_constipation with 32608 nan values\n",
      "Dropping pm_gastro_problems_crohns_disease_or_ulcerative_colitis with 32608 nan values\n",
      "Dropping pm_gastro_problems with 32608 nan values\n",
      "Dropping pm_experience_worth_it with 32608 nan values\n",
      "Dropping pm_ethnicity with 32608 nan values\n",
      "Dropping pm_email with 32608 nan values\n",
      "Dropping pm_education with 32608 nan values\n",
      "Dropping pm_concern with 32608 nan values\n",
      "Dropping pm_age with 32608 nan values\n",
      "Dropping plant_protein_frequency with 29149 nan values\n",
      "Dropping physical_specimen_location with only one unique value\n",
      "Dropping other_animals_free_text with 32608 nan values\n",
      "Dropping oils_frequency_soy with 32608 nan values\n",
      "Dropping oils_frequency_oxalate with 32608 nan values\n",
      "Dropping name with 32608 nan values\n",
      "Dropping lowgrain_diet_type with 25347 nan values\n",
      "Dropping longitude with 29173 nan values\n",
      "Dropping living_status with 32590 nan values\n",
      "Dropping latitude with 29173 nan values\n",
      "Dropping keep_sample_for_thdmi with 30422 nan values\n",
      "Dropping ibd_diagnosis_refined with 31907 nan values\n",
      "Dropping ibd_diagnosis with 32608 nan values\n",
      "Dropping humans_free_text with 32608 nan values\n",
      "Dropping hours_outside with 32589 nan values\n",
      "Dropping host_weight_units with only one unique value\n",
      "Dropping host_taxid with only one unique value\n",
      "Dropping host_scientific_name with 32596 nan values\n",
      "Dropping host_height_units with only one unique value\n",
      "Dropping host_common_name with only one unique value\n",
      "Dropping host_age_units with only one unique value\n",
      "Dropping height_units with 32608 nan values\n",
      "Dropping height_cm with 32608 nan values\n",
      "Dropping geo_loc_name with 29169 nan values\n",
      "Dropping food_type with 32590 nan values\n",
      "Dropping food_special_unspecified with 29295 nan values\n",
      "Dropping food_special_organic with 29295 nan values\n",
      "Dropping food_special_grain_free with 29295 nan values\n",
      "Dropping food_special with 32608 nan values\n",
      "Dropping food_source_wild_food with 29295 nan values\n",
      "Dropping food_source_unspecified with 29295 nan values\n",
      "Dropping food_source_pet_store_food with 29295 nan values\n",
      "Dropping food_source_human_food with 29295 nan values\n",
      "Dropping food_source with 32608 nan values\n",
      "Dropping fermented_produce_personal_other_1 with 32202 nan values\n",
      "Dropping fermented_produce_personal_other with 32608 nan values\n",
      "Dropping fermented_produce_personal_fish_sauce with only one unique value\n",
      "Dropping fermented_produce_personal with 32608 nan values\n",
      "Dropping fermented_produce_commercial_tempeh with only one unique value\n",
      "Dropping fermented_produce_commercial_other_1 with 32202 nan values\n",
      "Dropping fermented_produce_commercial_other with 32608 nan values\n",
      "Dropping fermented_produce_commercial_kombucha with only one unique value\n",
      "Dropping fermented_produce_commercial_kefir_water with only one unique value\n",
      "Dropping fermented_produce_commercial_fish_sauce with only one unique value\n",
      "Dropping fermented_produce_commercial_fermented_tofu with only one unique value\n",
      "Dropping fermented_produce_commercial_fermented_beansmisonatto with only one unique value\n",
      "Dropping fermented_produce_commercial_cottage_cheese with only one unique value\n",
      "Dropping fermented_produce_commercial_chicha with only one unique value\n",
      "Dropping fermented_produce_commercial with 32608 nan values\n",
      "Dropping fermented_other with 32608 nan values\n",
      "Dropping fermented_increased with 31545 nan values\n",
      "Dropping fermented_frequency with 31507 nan values\n",
      "Dropping fermented_consumed_other_1 with 32202 nan values\n",
      "Dropping fermented_consumed_other with 32608 nan values\n",
      "Dropping fermented_consumed with 32608 nan values\n",
      "Dropping elevation with 29448 nan values\n",
      "Dropping economic_region with 32606 nan values\n",
      "Dropping diet with 32590 nan values\n",
      "Dropping diabetes_type with 32125 nan values\n",
      "Dropping depression_bipolar_schizophrenia with 28177 nan values\n",
      "Dropping dark_mode_on with 32608 nan values\n",
      "Dropping covid_worrying with 29052 nan values\n",
      "Dropping covid_worried_sleep with 29063 nan values\n",
      "Dropping covid_waking_up_early with 29175 nan values\n",
      "Dropping covid_symptoms_stay_home with 31128 nan values\n",
      "Dropping covid_symptoms_other with 32608 nan values\n",
      "Dropping covid_suspected_positive_date with 32608 nan values\n",
      "Dropping covid_suspected_positive with 29135 nan values\n",
      "Dropping covid_sleep_pattern with 29027 nan values\n",
      "Dropping covid_sleep_interference with 29091 nan values\n",
      "Dropping covid_rideshare with 29077 nan values\n",
      "Dropping covid_quality_of_life with 29096 nan values\n",
      "Dropping covid_patient_care_seven_days_confirmed with 31777 nan values\n",
      "Dropping covid_patient_care_seven_days with 31652 nan values\n",
      "Dropping covid_patient_care_ppe with 32417 nan values\n",
      "Dropping covid_patient_care with 29037 nan values\n",
      "Dropping covid_occupation with 32608 nan values\n",
      "Dropping covid_level_of_wellbeing with 29047 nan values\n",
      "Dropping covid_left_home with 29053 nan values\n",
      "Dropping covid_interest_pleasure with 29057 nan values\n",
      "Dropping covid_difficulty_staying_asleep with 29173 nan values\n",
      "Dropping covid_difficulty_falling_asleep with 29149 nan values\n",
      "Dropping covid_depressed with 29055 nan values\n",
      "Dropping covid_anxious with 29049 nan values\n",
      "Dropping country with 32543 nan values\n",
      "Dropping coprophage with 32590 nan values\n",
      "Dropping census_region with 32591 nan values\n",
      "Dropping cancer_treatment with 31241 nan values\n",
      "Dropping body_site with 32608 nan values\n",
      "Dropping body_product with 32608 nan values\n",
      "Dropping bmi with 32608 nan values\n",
      "Dropping beet_frequency with 29183 nan values\n",
      "Dropping atypical_sleep_time with 32608 nan values\n",
      "Dropping artificial_sweeteners_food with 32608 nan values\n",
      "Dropping artificial_gi_disorders with 32608 nan values\n",
      "Dropping artificial_gi_disorder_types_unspecified with 32608 nan values\n",
      "Dropping artificial_gi_disorder_types_stomachache with 32608 nan values\n",
      "Dropping artificial_gi_disorder_types_soft_stools with 32608 nan values\n",
      "Dropping artificial_gi_disorder_types_diarrhea with 32608 nan values\n",
      "Dropping artificial_gi_disorder_types_constipation with 32608 nan values\n",
      "Dropping animal_type_free_text with 32608 nan values\n",
      "Dropping animal_type with 32589 nan values\n",
      "Dropping animal_origin with 32590 nan values\n",
      "Dropping animal_gender with 32590 nan values\n",
      "Dropping animal_free_text with 32608 nan values\n",
      "Dropping animal_age with 32590 nan values\n",
      "Dropping age_years with 32596 nan values\n"
     ]
    }
   ],
   "source": [
    "# Drop boring columns\n",
    "for col in reversed(adata.obs.columns):\n",
    "    vals = adata.obs[col]\n",
    "    if vals.dtype.name == \"category\":\n",
    "        vals = vals.str.lower()\n",
    "        nan_indicator = vals.isin(nan_master)\n",
    "        n_nans = nan_indicator.sum()\n",
    "        vals_filtered = vals[~nan_indicator]\n",
    "    else:\n",
    "        nan_indicator = np.isnan(vals)\n",
    "        n_nans = nan_indicator.sum()\n",
    "    if n_nans > 20000:\n",
    "        print(f\"Dropping {col} with {n_nans} nan values\")\n",
    "        adata.obs.drop(columns=col, inplace=True)\n",
    "\n",
    "    elif vals[~nan_indicator].nunique() == 1:\n",
    "        print(f\"Dropping {col} with only one unique value\")\n",
    "        adata.obs.drop(columns=col, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/phil/hdt\")\n",
    "\n",
    "from src.tree import HyperbolicDecisionTreeClassifier\n",
    "from src.forest import HyperbolicRandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0650a98711444ce19d09b9b5fc5b8656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acid_reflux\n",
      "DT: 0.5439 ± 0.0284\n",
      "RF: 0.5874 ± 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.33it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.38it/s]\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.30it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.41it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDT: 0.5100 ± 0.0107\n",
      "HRF: 0.5297 ± 0.0072\n",
      "DT: 0.5610 ± 0.0482\n",
      "RF: 0.5929 ± 0.0768\n",
      "DT: 0.5584 ± 0.0378\n",
      "RF: 0.5985 ± 0.0776\n",
      "acne_medication\n",
      "DT: 0.5439 ± 0.0284\n",
      "RF: 0.5874 ± 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:31<00:00,  3.16it/s]\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.30it/s]\n",
      "100%|██████████| 100/100 [00:32<00:00,  3.03it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.53it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDT: 0.5100 ± 0.0107\n",
      "HRF: 0.5297 ± 0.0072\n",
      "DT: 0.5610 ± 0.0482\n",
      "RF: 0.5929 ± 0.0768\n",
      "DT: 0.5584 ± 0.0378\n",
      "RF: 0.5985 ± 0.0776\n",
      "acne_medication_otc\n",
      "DT: 0.5439 ± 0.0284\n",
      "RF: 0.5874 ± 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:32<00:00,  3.11it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.21it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.36it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.52it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDT: 0.5100 ± 0.0107\n",
      "HRF: 0.5297 ± 0.0072\n",
      "DT: 0.5610 ± 0.0482\n",
      "RF: 0.5929 ± 0.0768\n",
      "DT: 0.5584 ± 0.0378\n",
      "RF: 0.5985 ± 0.0776\n",
      "add_adhd\n",
      "DT: 0.5439 ± 0.0284\n",
      "RF: 0.5874 ± 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.27it/s]\n",
      "100%|██████████| 100/100 [00:32<00:00,  3.09it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.42it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDT: 0.5100 ± 0.0107\n",
      "HRF: 0.5297 ± 0.0072\n",
      "DT: 0.5610 ± 0.0482\n",
      "RF: 0.5929 ± 0.0768\n",
      "DT: 0.5584 ± 0.0378\n",
      "RF: 0.5985 ± 0.0776\n",
      "age_cat\n",
      "DT: 0.5439 ± 0.0284\n",
      "RF: 0.5874 ± 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.27it/s]\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.29it/s]\n",
      "100%|██████████| 100/100 [00:32<00:00,  3.05it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.53it/s]\n",
      " 78%|███████▊  | 78/100 [00:24<00:06,  3.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m hdt_score \u001b[39m=\u001b[39m cross_val_score(hdt, X, y, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m hrf \u001b[39m=\u001b[39m HyperbolicRandomForestClassifier(\n\u001b[1;32m     39\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, min_dist\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 41\u001b[0m hrf_score \u001b[39m=\u001b[39m cross_val_score(hrf, X, y, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHDT: \u001b[39m\u001b[39m{\u001b[39;00mhdt_score\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ± \u001b[39m\u001b[39m{\u001b[39;00mhdt_score\u001b[39m.\u001b[39mstd()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHRF: \u001b[39m\u001b[39m{\u001b[39;00mhrf_score\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ± \u001b[39m\u001b[39m{\u001b[39;00mhrf_score\u001b[39m.\u001b[39mstd()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/hdt/src/forest.py:57\u001b[0m, in \u001b[0;36mHyperbolicRandomForestClassifier.fit\u001b[0;34m(self, X, y, use_tqdm, njobs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mfor\u001b[39;00m tree \u001b[39min\u001b[39;00m trees:\n\u001b[1;32m     56\u001b[0m         X_sample, y_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_subsample(X, y)\n\u001b[0;32m---> 57\u001b[0m         tree\u001b[39m.\u001b[39;49mfit(X_sample, y_sample)\n\u001b[1;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/hdt/src/tree.py:99\u001b[0m, in \u001b[0;36mHyperbolicDecisionTreeClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperbolic \u001b[39melse\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim)\n\u001b[0;32m---> 99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_node(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, depth\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/hdt/src/tree.py:88\u001b[0m, in \u001b[0;36mHyperbolicDecisionTreeClassifier._fit_node\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     86\u001b[0m node \u001b[39m=\u001b[39m HyperbolicDecisionNode(feature\u001b[39m=\u001b[39mbest_dim, theta\u001b[39m=\u001b[39mbest_theta)\n\u001b[1;32m     87\u001b[0m left, right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_split(X\u001b[39m=\u001b[39mX, dim\u001b[39m=\u001b[39mbest_dim, theta\u001b[39m=\u001b[39mbest_theta)\n\u001b[0;32m---> 88\u001b[0m node\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_node(X\u001b[39m=\u001b[39;49mX[left], y\u001b[39m=\u001b[39;49my[left], depth\u001b[39m=\u001b[39;49mdepth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     89\u001b[0m node\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_node(X\u001b[39m=\u001b[39mX[right], y\u001b[39m=\u001b[39my[right], depth\u001b[39m=\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/hdt/src/tree.py:89\u001b[0m, in \u001b[0;36mHyperbolicDecisionTreeClassifier._fit_node\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     87\u001b[0m left, right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_split(X\u001b[39m=\u001b[39mX, dim\u001b[39m=\u001b[39mbest_dim, theta\u001b[39m=\u001b[39mbest_theta)\n\u001b[1;32m     88\u001b[0m node\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_node(X\u001b[39m=\u001b[39mX[left], y\u001b[39m=\u001b[39my[left], depth\u001b[39m=\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m node\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_node(X\u001b[39m=\u001b[39;49mX[right], y\u001b[39m=\u001b[39;49my[right], depth\u001b[39m=\u001b[39;49mdepth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/hdt/src/tree.py:76\u001b[0m, in \u001b[0;36mHyperbolicDecisionTreeClassifier._fit_node\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m theta \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_candidates(X\u001b[39m=\u001b[39mX, dim\u001b[39m=\u001b[39mdim):\n\u001b[1;32m     75\u001b[0m     left, right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_split(X\u001b[39m=\u001b[39mX, dim\u001b[39m=\u001b[39mdim, theta\u001b[39m=\u001b[39mtheta)\n\u001b[0;32m---> 76\u001b[0m     score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_information_gain(left, right, y)\n\u001b[1;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m score \u001b[39m>\u001b[39m best_score:\n\u001b[1;32m     78\u001b[0m         best_dim, best_theta, best_score \u001b[39m=\u001b[39m dim, theta, score\n",
      "File \u001b[0;32m~/hdt/src/tree.py:37\u001b[0m, in \u001b[0;36mHyperbolicDecisionTreeClassifier._information_gain\u001b[0;34m(self, left, right, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gini\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39msum(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_probs(y) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_information_gain\u001b[39m(\u001b[39mself\u001b[39m, left, right, y):\n\u001b[1;32m     38\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(y)\n\u001b[1;32m     39\u001b[0m     n_l, n_r \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(y[left]), \u001b[39mlen\u001b[39m(y[right])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%prun\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"column\",\n",
    "        \"embedding\",\n",
    "        \"dt_score\",\n",
    "        \"dt_score_std\",\n",
    "        \"rf_score\",\n",
    "        \"rf_score_std\",\n",
    "        \"hdt_score\",\n",
    "        \"hdt_score_std\",\n",
    "        \"hrf_score\",\n",
    "        \"hrf_score_std\",\n",
    "    ]\n",
    ")\n",
    "for col in tqdm(adata.obs.columns):\n",
    "    print(col)\n",
    "    if adata.obs.dtypes[col].name == \"category\":\n",
    "        for embedding in [\"hyp_mix_64\", \"euc_mix_64\", \"pca_64\"]:\n",
    "            X, y = classify(\n",
    "                column=column, data=adata.obsm[embedding], balance=True, seed=42\n",
    "            )\n",
    "\n",
    "            dt = DecisionTreeClassifier()\n",
    "            dt_score = cross_val_score(dt, X, y, cv=5, scoring=\"accuracy\")\n",
    "            rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "            rf_score = cross_val_score(rf, X, y, cv=5, scoring=\"accuracy\")\n",
    "            print(f\"DT: {dt_score.mean():.4f} ± {dt_score.std():.4f}\")\n",
    "            print(f\"RF: {rf_score.mean():.4f} ± {rf_score.std():.4f}\")\n",
    "\n",
    "            if embedding == \"hyp_mix_64\":\n",
    "                hdt = HyperbolicDecisionTreeClassifier(min_dist=1e-3)\n",
    "                hdt_score = cross_val_score(hdt, X, y, cv=5, scoring=\"accuracy\")\n",
    "                hrf = HyperbolicRandomForestClassifier(\n",
    "                    n_estimators=100, min_dist=1e-3\n",
    "                )\n",
    "                hrf_score = cross_val_score(hrf, X, y, cv=5, scoring=\"accuracy\")\n",
    "                print(f\"HDT: {hdt_score.mean():.4f} ± {hdt_score.std():.4f}\")\n",
    "                print(f\"HRF: {hrf_score.mean():.4f} ± {hrf_score.std():.4f}\")\n",
    "            else:\n",
    "                hdt_score = np.nan * np.ones(5)\n",
    "                hrf_score = np.nan * np.ones(5)\n",
    "\n",
    "            results.loc[len(results)] = {\n",
    "                \"column\": col,\n",
    "                \"embedding\": embedding,\n",
    "                \"dt_score\": dt_score.mean(),\n",
    "                \"dt_score_std\": dt_score.std(),\n",
    "                \"rf_score\": rf_score.mean(),\n",
    "                \"rf_score_std\": rf_score.std(),\n",
    "                \"hdt_score\": hdt_score.mean(),\n",
    "                \"hdt_score_std\": hdt_score.std(),\n",
    "                \"hrf_score\": hrf_score.mean(),\n",
    "                \"hrf_score_std\": hrf_score.std(),\n",
    "            }\n",
    "\n",
    "results.to_csv(\"data/classification_results_bycol_64dim.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "americangut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
